\documentclass[12pt,a4paper]{article}

% Paquetes esenciales
\usepackage{graphicx}
\usepackage{setspace}
\usepackage[numbers,sort&compress]{natbib}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{hyperref}
\usepackage{amsmath,amssymb}
\usepackage{geometry}
\usepackage{longtable}
\usepackage{caption}

% Configuración de márgenes
\geometry{
    a4paper,
    left=3cm,
    right=2.5cm,
    top=2.5cm,
    bottom=2.5cm
}

% Configuración de hyperref
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
    pdftitle={Propuesta TFM - Sistema Multiagente para Verificación de Hechos},
    pdfauthor={Begoña Echavarren Sánchez}
}

% Espaciado
\onehalfspacing

%%%%%%%%%%%%%%%%%%%%
% INICIO DOCUMENTO %
%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%
% PORTADA   %
%%%%%%%%%%%%%
\begin{titlepage}
    \begin{center}
    \vspace*{0.5cm}

    \includegraphics[width=0.6\textwidth]{figs/uoc_logo.png}

    \vspace{1.5cm}

    {\Huge \textbf{Propuesta de Trabajo Final de Máster}}

    \vspace{2cm}

    {\LARGE \textbf{Sistema Multiagente para Verificación Automática de Hechos en Videos de YouTube}}

    \vspace{2.5cm}

    \textbf{\large Begoña Echavarren Sánchez}

    \vspace{0.5cm}

    \textit{Tutor: Josep-Anton Mir Tutusaus}

    \vspace{2cm}

    {\large Máster Universitario en Ciencia de Datos}

    {\large Universitat Oberta de Catalunya}

    \vspace{1cm}

    {\large PEC 1 - Definición del TFM}

    \vspace{0.5cm}

    {\large Octubre 2025}

    \end{center}
\end{titlepage}

\newpage
\pagenumbering{arabic}

%%%%%%%%%%%%%%%%%%%%%
% 1. TÍTULO         %
%%%%%%%%%%%%%%%%%%%%%
\section{Título del proyecto}

\textbf{Sistema Multiagente para Verificación Automática de Hechos en Videos de YouTube}

%%%%%%%%%%%%%%%%%%%%%
% 2. PALABRAS CLAVE %
%%%%%%%%%%%%%%%%%%%%%
\section{Palabras clave}

fact-checking automatizado, verificación de hechos, LLMs, modelos de lenguaje, sistemas multiagente, procesamiento de lenguaje natural, desinformación, recuperación de información, análisis de evidencias

%%%%%%%%%%%%%%%%%%%%%
% 3. RESUMEN        %
%%%%%%%%%%%%%%%%%%%%%
\section{Resumen}

La desinformación en plataformas de video constituye un desafío creciente en la sociedad digital actual. Este trabajo propone el diseño, implementación y evaluación de un sistema end-to-end de verificación automática de hechos (fact-checking) para videos de YouTube, basado en una arquitectura multiagente que integra modelos de lenguaje de gran escala (LLMs), técnicas de procesamiento de lenguaje natural y recuperación de información en línea.

El sistema propuesto opera mediante un pipeline de cinco componentes especializados: (1) extracción de transcripciones de video, (2) identificación automática de afirmaciones factuales mediante LLMs, (3) generación de consultas de búsqueda optimizadas, (4) recuperación y evaluación de evidencias desde fuentes web, y (5) síntesis de veredictos razonados con evaluación de confianza. Cada componente procesa información estructurada garantizando robustez y trazabilidad en todo el proceso.

La implementación técnica se desarrollará en Python utilizando frameworks modernos como Pydantic AI, FastAPI, entre otros, junto con modelos de lenguaje tanto comerciales como de código abierto. El proyecto incluirá una interfaz web desarrollada en React con streaming en tiempo real mediante Server-Sent Events (SSE), proporcionando una experiencia de usuario interactiva durante el proceso de verificación.

Un componente fundamental del trabajo será la evaluación comparativa de diferentes LLMs y enfoques arquitecturales. Se implementarán técnicas de evaluación específicas para modelos de lenguaje, métricas de rendimiento cuantitativas y protocolos de evaluación cualitativa para determinar las configuraciones óptimas del sistema. El análisis incluirá estudios de caso en diferentes temáticas de videos (economía, geopolítica, ciencia) con especial atención a los compromisos entre coste, calidad y latencia en las distintas aproximaciones evaluadas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 4. DESCRIPCIÓN Y JUSTIFICACIÓN  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Descripción y justificación del proyecto}

\subsection{Contexto del problema}

La desinformación en plataformas de video constituye un desafío creciente en la sociedad digital actual. YouTube, con más de 2 mil millones de usuarios activos mensuales, se ha convertido en una fuente primaria de información para millones de personas. Sin embargo, la ausencia de mecanismos efectivos de verificación de información permite la propagación de afirmaciones incorrectas o engañosas a escala masiva.

El problema central que aborda este proyecto es la \textbf{falta de mecanismos automatizados y accesibles para verificar afirmaciones factuales en contenido audiovisual de plataformas digitales}, específicamente videos de YouTube. Los usuarios individuales carecen de herramientas para verificar afirmaciones de forma sistemática, mientras que la verificación manual requiere habilidades avanzadas, tiempo considerable y recursos no siempre disponibles.

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{./figs/system_architecture.png}
\caption{Arquitectura del sistema multiagente propuesto. Pipeline de cinco componentes especializados procesando secuencialmente desde transcripción hasta veredicto final.}
\label{fig:arquitectura}
\end{figure}

\subsection{Relevancia e importancia}

Este proyecto es relevante por múltiples razones:

\begin{itemize}
    \item \textbf{Impacto social:} La desinformación erosiona la confianza en instituciones, influye en decisiones políticas y afecta la salud pública \citep{wardle2017information, benkler2018network}. Un sistema automatizado de verificación puede contribuir a mitigar estos efectos.

    \item \textbf{Desafío tecnológico:} El proyecto integra múltiples áreas de investigación en ciencia de datos: procesamiento de lenguaje natural, recuperación de información, evaluación de credibilidad de fuentes y razonamiento automático. Representa un problema técnicamente complejo que requiere soluciones innovadoras.

    \item \textbf{Escalabilidad necesaria:} El volumen de contenido generado diariamente (más de 500 horas de video por minuto en YouTube) hace inviable el fact-checking puramente humano. La automatización es necesaria para abordar el problema a escala.

    \item \textbf{Alfabetización mediática:} Herramientas que empoderan a ciudadanos para evaluar críticamente información promueven el pensamiento crítico y fortalecen la alfabetización mediática en la sociedad.
\end{itemize}

\subsection{Estado actual de soluciones existentes}

Actualmente existen tres enfoques principales para la verificación de hechos:

\begin{enumerate}
    \item \textbf{Fact-checking manual:} Organizaciones como Newtral, Maldita.es y FactCheck.org emplean periodistas especializados. Este enfoque garantiza calidad pero está limitado por recursos humanos y es inherentemente lento.

    \item \textbf{Sistemas académicos:} Proyectos como FEVER \citep{thorne2018fever}, FEVEROUS \citep{aly2021feverous} y trabajos recientes sobre verificación científica \citep{wadden2020scifact} operan principalmente sobre bases de conocimiento estructuradas (Wikipedia) o requieren datasets curados específicos. No están disponibles como productos utilizables por usuarios finales y tienen alcance limitado.

    \item \textbf{APIs de verificación:} Google Fact Check Tools API agrega fact-checks ya publicados por organizaciones profesionales, pero solo cubre contenido previamente verificado manualmente. No proporciona verificación nueva de contenido no examinado.
\end{enumerate}

\textbf{Limitaciones identificadas:} Ninguno de estos enfoques proporciona verificación automatizada end-to-end para contenido audiovisual generado continuamente por usuarios en plataformas como YouTube. Existe una brecha entre la investigación académica (datasets estáticos, dominios limitados) y herramientas prácticas accesibles para usuarios finales.

\subsection{Propuesta y contribución esperada}

Este proyecto desarrollará un \textbf{sistema funcional end-to-end} que procese videos de YouTube mediante:

\begin{itemize}
    \item Extracción automática de transcripciones
    \item Identificación de afirmaciones factuales verificables mediante LLMs
    \item Recuperación de evidencias desde múltiples fuentes web
    \item Evaluación de credibilidad de fuentes y postura de evidencias
    \item Generación de veredictos fundamentados con explicaciones transparentes
    \item Interfaz web accesible para usuarios finales
\end{itemize}

\textbf{Contribuciones esperadas:}

\begin{enumerate}
    \item \textbf{Sistema completo operativo:} A diferencia de prototipos académicos, se desarrollará una aplicación funcional con interfaz web.

    \item \textbf{Análisis comparativo de LLMs:} Evaluación empírica de modelos comerciales (GPT-4o-mini) versus open-source (Ollama Qwen 3), documentando compromisos entre coste, rendimiento y calidad.

    \item \textbf{Metodología de evaluación:} Protocolo de evaluación cualitativa y cuantitativa aplicable a sistemas similares.

    \item \textbf{Análisis de implicaciones éticas:} Estudio de sesgos, limitaciones y riesgos de la automatización del fact-checking.
\end{enumerate}

\subsection{Alcance del proyecto}

\textbf{Incluye:}
\begin{itemize}
    \item Videos de YouTube con transcripciones disponibles (subtítulos automáticos o manuales)
    \item Afirmaciones factuales verificables mediante fuentes web públicas
    \item Contenido principalmente en inglés, con soporte experimental para español
    \item Procesamiento bajo demanda de videos individuales
\end{itemize}

\textbf{No incluye:}
\begin{itemize}
    \item Generación propia de transcripciones desde audio (speech-to-text)
    \item Verificación de contenido visual (detección de deepfakes, manipulación de imágenes)
    \item Sistema de caché o base de datos persistente de verificaciones
    \item Verificación en tiempo real o procesamiento batch a gran escala
    \item Contenido de plataformas distintas a YouTube
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 5. MOTIVACIÓN PERSONAL  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivación personal}

Mi interés en este proyecto surge de la confluencia de tres factores principales:

\textbf{Experiencia profesional:} Como Machine Learning Engineer con más de 5 años de experiencia en Data Science, he trabajado en proyectos que combinan NLP, APIs y sistemas productivos. Este TFM me permite aplicar y profundizar conocimientos en un contexto de alto impacto social, mientras exploro tecnologías emergentes como LLMs y arquitecturas multiagente.

\textbf{Intereses personales:} Soy consumidor habitual de contenido educativo en YouTube sobre economía, geopolítica y ciencia. Con frecuencia encuentro afirmaciones que requieren verificación pero carezco de herramientas eficientes para hacerlo sistemáticamente. Este proyecto nace de una necesidad personal real: crear la herramienta que me gustaría tener como usuario.

\textbf{Objetivos de desarrollo:} El proyecto combina aspectos de investigación (estado del arte en fact-checking, evaluación de LLMs) con ingeniería de software aplicada (arquitectura escalable, despliegue de aplicaciones). Esta dualidad se alinea con mi visión profesional de transitar desde roles puramente técnicos hacia posiciones que combinan investigación aplicada y desarrollo de producto.

Adicionalmente, considero que el fact-checking automatizado representa una contribución al bien social. En una era donde la desinformación tiene consecuencias reales en salud pública, democracia y cohesión social, desarrollar herramientas que fomenten el pensamiento crítico y la alfabetización mediática es una responsabilidad que me motiva profundamente.

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 6. OBJETIVOS            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Objetivos del proyecto}

\subsection{Hipótesis u objetivo principal}

\textbf{Objetivo principal:} Diseñar, implementar y evaluar un sistema multiagente basado en modelos de lenguaje capaz de verificar automáticamente afirmaciones factuales en videos de YouTube mediante recuperación y análisis de evidencias web, generando veredictos fundamentados con estimación de confianza que sean útiles para usuarios finales.

\subsection{Objetivos específicos (preguntas de investigación)}

\textbf{OE1. Diseño de arquitectura multiagente}
\begin{itemize}
    \item Definir pipeline de procesamiento con componentes especializados
    \item Establecer esquemas de datos estructurados para comunicación inter-agente
    \item Diseñar sistema de coordinación y flujo de información
\end{itemize}

\textbf{OE2. Implementación de componentes del sistema}
\begin{itemize}
    \item Desarrollar módulo de extracción de transcripciones desde YouTube
    \item Implementar agente de identificación de claims con clasificación de relevancia
    \item Crear generador de consultas de búsqueda optimizadas
    \item Desarrollar sistema de web scraping con evaluación de fiabilidad de fuentes
    \item Implementar generador de veredictos con razonamiento explicable
\end{itemize}

\textbf{OE3. Optimización de uso de LLMs}
\begin{itemize}
    \item Comparar rendimiento entre modelos comerciales (GPT-4o-mini) y open-source (Ollama Qwen 3)
    \item Analizar compromisos entre coste, latencia y calidad de outputs
    \item Evaluar estrategias de optimización de prompts y structured outputs
\end{itemize}

\textbf{OE4. Evaluación del sistema}
\begin{itemize}
    \item Definir métricas de rendimiento técnico (tiempo, coste, throughput)
    \item Establecer protocolos de evaluación cualitativa de veredictos
    \item Realizar estudios de caso en diferentes temáticas
    \item Analizar limitaciones y casos de fallo del sistema
\end{itemize}

\textbf{OE5. Implementación de sistema end-to-end}
\begin{itemize}
    \item Desarrollar API REST con streaming en tiempo real
    \item Crear interfaz web intuitiva para usuarios finales
    \item Garantizar reproducibilidad y documentación exhaustiva
\end{itemize}

\textbf{OE6. Análisis de implicaciones éticas}
\begin{itemize}
    \item Identificar sesgos potenciales en selección de fuentes y generación de veredictos
    \item Analizar riesgos de automatización de fact-checking
    \item Proponer salvaguardas y mejores prácticas
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 7. CCEG Y ODS                          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Competencia de Compromiso Ético y Global (CCEG)}

Esta sección evalúa el impacto del proyecto en las tres dimensiones de la Competencia de Compromiso Ético y Global establecida por la UOC.

\subsection{Sostenibilidad y Objetivos de Desarrollo Sostenible (ODS)}

El uso de modelos de lenguaje de gran escala implica un consumo energético significativo. Este proyecto aborda explícitamente esta preocupación mediante:

\begin{itemize}
    \item \textbf{Evaluación de alternativas eficientes:} Comparación entre modelos comerciales cloud y modelos open-source ejecutables localmente, priorizando modelos locales durante experimentación.

    \item \textbf{Análisis de compromisos:} Documentación transparente del consumo de recursos (tokens procesados, tiempo de ejecución, coste económico).

    \item \textbf{Optimización:} Refinamiento de prompts para minimizar tokens procesados sin sacrificar calidad.
\end{itemize}

\textbf{Relación con ODS:}
\begin{itemize}
    \item \textbf{ODS 4 (Educación de Calidad):} Herramienta de alfabetización mediática que promueve pensamiento crítico.
    \item \textbf{ODS 16 (Paz, Justicia e Instituciones Sólidas):} Combate la desinformación que erosiona instituciones democráticas.
    \item \textbf{ODS 10 (Reducción de Desigualdades):} Democratiza acceso a verificación de hechos.
\end{itemize}

En las conclusiones se incluirá análisis crítico sobre si la automatización justifica el consumo energético frente a beneficios sociales.

\subsection{Comportamiento ético y responsabilidad social}

\textbf{Impactos éticos identificados y estrategias de mitigación:}

\textbf{(1) Automatización y empleo:} El sistema podría percibirse como amenaza para verificadores profesionales. \textit{Estrategia:} Posicionamiento como herramienta de apoyo que automatiza pasos preliminares, permitiendo a profesionales enfocarse en análisis complejos que requieren juicio humano.

\textbf{(2) Sesgo algorítmico:} Los LLMs pueden perpetuar sesgos presentes en datos de entrenamiento. \textit{Mitigación:} Transparencia total en fuentes consultadas, presentación de evidencias con diferentes posturas, evaluación explícita de confianza en veredictos, y advertencias claras sobre limitaciones.

\textbf{(3) Riesgo de amplificación:} Al citar afirmaciones incorrectas durante verificación, existe riesgo de amplificar desinformación. \textit{Mitigación:} Presentación siempre contextualizada con veredicto, no indexación pública de claims individuales sin contexto, enfoque en proceso educativo más que en listados de falsedades.

\textbf{(4) Privacidad:} El proyecto respeta políticas de YouTube y no procesa contenido privado ni viola términos de uso de plataformas.

Como profesional de Data Science, este proyecto se adhiere a principios deontológicos de transparencia, no maleficencia, beneficencia social y responsabilidad ante consecuencias imprevistas.

\subsection{Diversidad, género y derechos humanos}

\textbf{Accesibilidad:} La interfaz web se diseñará siguiendo principios WCAG 2.1: contraste de colores adecuado, navegación por teclado, textos alternativos para elementos visuales, diseño responsive adaptable a diferentes dispositivos.

\textbf{Diversidad lingüística:} Se reconoce que los modelos LLM tienen mejor rendimiento en inglés. Mitigación mediante soporte experimental para español y documentación explícita de limitaciones lingüísticas.

\textbf{Diversidad de perspectivas:} Las fuentes web indexadas pueden tener sesgo geográfico/cultural (predominancia de contenido occidental). El sistema evaluará diversidad de perspectivas cuando estén disponibles y documentará esta limitación.

\textbf{Derechos fundamentales:}
\begin{itemize}
    \item \textbf{Derecho a la información:} Impacto positivo al facilitar acceso a verificación.
    \item \textbf{Libertad de expresión:} El sistema no censura contenido, solo proporciona contexto adicional.
    \item \textbf{Privacidad:} No procesa datos personales ni información identificable de usuarios.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 8. METODOLOGÍA          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metodología}

\subsection{Estrategia de investigación}

Este proyecto adopta una metodología de \textbf{Investigación y Desarrollo (Design Science Research)}, combinando investigación en ciencia de datos con ingeniería de software aplicada.

La estrategia seleccionada es el \textbf{desarrollo end-to-end con evaluación comparativa}, que combina implementación completa del pipeline (valor ingenieril), experimentación con diferentes modelos (valor investigativo), evaluación cuantitativa y cualitativa (rigor científico), e interfaz funcional (aplicabilidad real). Esta aproximación es apropiada porque:

\begin{itemize}
    \item El problema es complejo y multidisciplinar, requiriendo integración de NLP, recuperación de información y diseño de sistemas
    \item El resultado debe ser un sistema operativo funcional que aporte valor práctico, no solo análisis teórico
    \item Las decisiones técnicas se validan mediante experimentación empírica con diferentes configuraciones
    \item El desarrollo modular permite mejoras incrementales basadas en evaluación continua
\end{itemize}

\subsection{Metodología de desarrollo}

El sistema sigue una \textbf{arquitectura de pipeline} (Figura \ref{fig:arquitectura}) con cinco agentes especializados:

\begin{enumerate}
    \item \textbf{Transcriptor:} Extrae texto desde videos de YouTube usando APIs oficiales
    \item \textbf{Claim Extractor:} Identifica afirmaciones factuales verificables mediante LLMs
    \item \textbf{Query Generator:} Crea consultas de búsqueda optimizadas para motores de búsqueda
    \item \textbf{Online Search:} Recupera y evalúa evidencias web con análisis de credibilidad de fuentes
    \item \textbf{Output Generator:} Sintetiza veredictos fundamentados con razonamiento explicable
\end{enumerate}

Cada componente opera sobre esquemas de datos estructurados definidos con Pydantic, garantizando validación de tipos y contratos claros entre módulos.

\textbf{Proceso de desarrollo iterativo:}
\begin{enumerate}
    \item Implementación básica de cada componente individualmente
    \item Integración E2E del pipeline completo (MVP funcional)
    \item Refinamiento iterativo módulo por módulo
    \item Evaluación comparativa con diferentes configuraciones de LLMs
\end{enumerate}

\subsection{Técnicas y herramientas}

\textbf{Técnicas de Procesamiento de Lenguaje Natural:}
\begin{itemize}
    \item Prompting avanzado con LLMs (chain-of-thought, few-shot learning)
    \item Structured outputs mediante Pydantic AI para garantizar formato de respuestas
    \item Análisis de stance (postura de evidencias: apoya/refuta/neutral/no clara)
\end{itemize}

\textbf{Técnicas de Recuperación de Información:}
\begin{itemize}
    \item Web scraping con Selenium para extracción de contenido
    \item Evaluación de credibilidad mediante análisis WHOIS y características de sitio
    \item Estrategias de búsqueda diversificadas (múltiples consultas por claim)
\end{itemize}

\textbf{Stack Tecnológico:}
\begin{itemize}
    \item \textbf{Backend:} Python 3.12, Pydantic AI, FastAPI, Uvicorn
    \item \textbf{LLMs:} OpenAI GPT-4o-mini (comercial), Ollama con Qwen 3 (open-source local)
    \item \textbf{Frontend:} React 18.3, Vite, Tailwind CSS
    \item \textbf{Herramientas de desarrollo:} uv (gestión de dependencias), ruff (linting), mypy (type checking)
    \item \textbf{Control de versiones:} Git, GitHub
\end{itemize}

\subsection{Métodos de evaluación}

\textbf{Métricas cuantitativas:}
\begin{itemize}
    \item Tiempo de procesamiento por video
    \item Coste por verificación (tokens consumidos × precio por token)
    \item Número de fuentes recuperadas por claim
    \item Distribución de stances (evidencias a favor/contra/neutral)
\end{itemize}

\textbf{Evaluación cualitativa:}
\begin{itemize}
    \item Revisión manual de relevancia de claims extraídos
    \item Análisis de coherencia y fundamentación de veredictos
    \item Comparación con fact-checks profesionales cuando disponibles
    \item Identificación de casos de fallo y limitaciones
\end{itemize}

\textbf{Conjunto de evaluación:} Dataset de 15-20 videos diversos cubriendo diferentes temáticas (economía, política, ciencia, pseudociencia) y niveles de controversia.

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 9. PLANIFICACIÓN        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Planificación del proyecto}

\subsection{Cronograma general}

El proyecto se desarrolla durante el semestre académico 2025-2026, alineado con las entregas establecidas por el programa (Tabla \ref{tab:cronograma}).

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Hito} & \textbf{Entregable} & \textbf{Fecha límite} \\
\hline
M1 & Definición del TFM & 12 oct 2025 \\
M1 & Comité ética y confidencialidad & 12 oct 2025\\
M2 & Estado del arte & 2 nov 2025\\
M3 & Implementación & 14 dic 2025\\
M4 & Redacción memoria preliminar & 21 dic 2025\\
M4 & Redacción memoria final & 28 dic 2025\\
M4 & Presentación audiovisual & 6 ene 2026\\
M5 & Documentación al tribunal & 9 ene 2026\\
M5 & Defensa pública & 30 ene 2026\\
\hline
\end{tabular}
\caption{Cronograma general del proyecto}
\label{tab:cronograma}
\end{table}

\subsection{Descripción de fases}

\textbf{M1: Definición del TFM (hasta 12 oct 2025)}
\begin{itemize}
    \item Revisión bibliográfica sobre fact-checking automatizado y sistemas multiagente con LLMs
    \item Diseño de arquitectura del sistema y definición de componentes
    \item Selección de stack tecnológico
    \item Elaboración de propuesta de TFM (presente documento)
\end{itemize}

\textbf{M2: Estado del arte (hasta 2 nov 2025)}
\begin{itemize}
    \item Análisis en profundidad de soluciones existentes (FEVER, FEVEROUS, FactAgent)
    \item Revisión de técnicas de evaluación de LLMs
    \item Setup inicial del proyecto y estructura de repositorio
    \item Documentación del estado del arte
\end{itemize}

\textbf{M3: Implementación (hasta 14 dic 2025)}
\begin{itemize}
    \item Implementación de los cinco componentes del pipeline multiagente
    \item Integración end-to-end del sistema completo
    \item Desarrollo de API REST con streaming SSE
    \item Creación de interfaz web en React
    \item MVP funcional operativo
\end{itemize}

\textbf{M4: Evaluación y redacción (hasta 28 dic 2025)}
\begin{itemize}
    \item Evaluación comparativa de LLMs (GPT-4o-mini vs Ollama Qwen 3)
    \item Testing en conjunto de videos diversos
    \item Análisis de métricas y resultados
    \item Redacción de memoria del TFM
    \item Preparación de presentación audiovisual
\end{itemize}

\textbf{M5: Defensa (hasta 30 ene 2026)}
\begin{itemize}
    \item Entrega de documentación final al tribunal
    \item Preparación de defensa pública
    \item Defensa del TFM
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 10. BIBLIOGRAFÍA        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Bibliografía preliminar}

\nocite{*}
\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
