%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% GLOSSARY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Glossary}

This section defines the key terms used throughout this thesis.

%-------------------------------------------------------
\subsection{Terms}
%-------------------------------------------------------

\begin{description}

\item[Automated Fact-Checking] The use of computational methods to verify the accuracy of factual claims, typically involving claim detection, evidence retrieval, and verdict generation.

\item[Chain-of-Thought (CoT)] A prompting technique where a language model is instructed to explain its reasoning step by step before providing a final answer, improving accuracy on complex tasks.

\item[Check-Worthiness] A property of claims indicating they are both verifiable (can be confirmed or refuted with evidence) and important enough to warrant fact-checking effort.

\item[Claim Detection] The task of identifying factual statements within text that can be verified against external evidence, also known as claim extraction.

\item[Evidence Retrieval] The process of finding documents, passages, or data from external sources that support or refute a given claim.

\item[Fact-Checking] The process of verifying the accuracy of claims by examining available evidence, traditionally performed by journalists and specialized organizations.

\item[Hallucination] A phenomenon where language models generate plausible-sounding but factually incorrect or fabricated information.

\item[Information Retrieval (IR)] The field concerned with finding relevant documents or passages from large collections in response to a query.

\item[LLM-as-Judge] An evaluation paradigm where a language model assesses the quality of outputs from another model, providing scores or judgments on dimensions like coherence, factuality, or relevance.

\item[Misinformation] False or inaccurate information, regardless of intent, that spreads through media and digital platforms.

\item[Multi-Agent System] A computational system composed of multiple autonomous agents that interact and collaborate to accomplish tasks, often with specialized roles.

\item[Prompt Engineering] The practice of designing and optimizing input prompts to elicit desired behaviors from language models.

\item[Retrieval-Augmented Generation (RAG)] An approach that combines language model generation with external information retrieval to ground outputs in retrieved evidence.

\item[Stance Detection] The task of classifying the relationship between a piece of evidence and a claim, typically as supporting, refuting, or neutral.

\item[Structured Outputs] A pattern in LLM applications where model outputs are constrained to follow a predefined schema (e.g., JSON with specific fields), enabling reliable parsing and validation.

\item[Transcript] A text representation of spoken content from a video, including timing information for each segment.

\item[Verdict] The conclusion of a fact-checking analysis, typically categorizing a claim as supported (true), refuted (false), mixed, or uncertain.

\end{description}
