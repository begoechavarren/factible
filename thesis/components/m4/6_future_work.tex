%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CHAPTER 6: FUTURE WORK
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work}
\label{sec:future-work}

While the current implementation demonstrates the viability of automated fact-checking for YouTube videos, several limitations of the current approach motivate directions for future research. This section outlines these limitations alongside the corresponding opportunities for enhancement.

%-------------------------------------------------------
\subsection{Multilingual Support}
%-------------------------------------------------------

The system currently supports only English content, yet misinformation is a global phenomenon. Extending to languages such as Spanish, Portuguese, Hindi, or Arabic would require adapting prompts, identifying reliable sources in each language, and evaluating source credibility across different cultural and media contexts.

%-------------------------------------------------------
\subsection{Large Language Model Comparison}
%-------------------------------------------------------

Future studies should benchmark multiple commercial and local models (GPT-4 variants, Claude, Gemini, LLaMA, Qwen, Mistral) across pipeline components. Such comparisons would map cost-quality trade-offs and assess whether mixed deployments---where different models handle different stages---improve overall performance.

%-------------------------------------------------------
\subsection{Enhanced Prompt Engineering}
%-------------------------------------------------------

Maintaining a versioned prompt library with documented variants would make it easier to evolve instructions without rewriting code. Automated prompt tuning using evaluation feedback and domain-specific templates (scientific vs. political claims) could further improve consistency.

%-------------------------------------------------------
\subsection{Enhanced Source Reliability Assessment}
%-------------------------------------------------------

Source reliability could be refined by incorporating publisher-level signals such as impact factors and retraction history for academic sources, topic-aware weighting that distinguishes science journalism from political commentary, and time-varying trust scores that account for reputation changes. Lightweight cross-referencing when conflicting evidence appears would further strengthen verdict quality.

%-------------------------------------------------------
\subsection{Handling Contested Claims}
%-------------------------------------------------------

The current system struggles with genuinely contested claims where reasonable sources disagree. Future approaches might explicitly detect and flag such claims as ``contested'' rather than attempting definitive verdicts, implement debate-style verification using multiple LLM agents with different perspectives, or develop specialized pipelines for political versus scientific claims. Incorporating user feedback could further refine handling of ambiguous cases.

%-------------------------------------------------------
\subsection{Production Deployment}
%-------------------------------------------------------

Transitioning from research prototype to production would involve cloud deployment with auto-scaling for handling concurrent users, user authentication and rate limiting to prevent abuse, and caching for transcripts and reliability assessments to reduce latency and costs. Monitoring infrastructure would ensure operational health, while a browser extension could enable seamless YouTube verification without leaving the platform.

%-------------------------------------------------------
\subsection{Extended Evaluation}
%-------------------------------------------------------

The current evaluation has constraints (single annotator, 30-video corpus, point-in-time results) that future work should address. A larger corpus of 100+ videos with multiple annotators would establish inter-annotator agreement baselines and enable more robust statistical conclusions. User studies could evaluate perceived usefulness and trust calibration, while longitudinal evaluation would track performance as LLMs and web content evolve over time.

%-------------------------------------------------------
\subsection{Multimodal Verification}
%-------------------------------------------------------

The current system operates only on transcript text, ignoring visual content. Future work could incorporate image and video frame analysis for visual claim verification, chart and graph interpretation for data-driven claims, speaker identification for credibility signals, and deepfake detection for authenticity verification.
